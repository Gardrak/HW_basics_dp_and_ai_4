### 4 Лабораторная работа по основам глубокого обучения и искусственного интеллекта   
Датасет был взят по ссылке: https://www.cs.toronto.edu/~kriz/cifar.html . Был удален из репозитория из-за большого объема.  
Из-за большого кол-ва редактирования кода, сделал **batch_size** и **epouch** маленькими(что врочем несильно увеличело скорость тренировки), но думаю, что это не критично для этой работы. Из-за это процент точности может быть ниже ожидаемого.  
Изначально хотел сохранить ООП путем разбиения утилит в отдельную папку, но после выполнения первого задания понял, что это лишнее. Оставил файл **Settings.py** для настройки основных параметров, необходимых для тренировки, а также несколько путей для сохранения картинок, результатов и датасета.  


## Задание 1: Сравнение CNN и полносвязных сетей  
# Сравнение на MNIST
Лучше всего показали себя модели **SimpleCNN** и **ResNetMNIST** с точностью в **99.05%** со временем **102.06s** и **118.90s** соответственно(см. **results/comparison_results.txt**).  
![Result ResNetMNIST](https://github.com/Gardrak/HW_basics_dp_and_ai_4/blob/main/plots/MNIST_ResNetMNIST_curves.png)  
![Result SimpleCNN](https://github.com/Gardrak/HW_basics_dp_and_ai_4/blob/main/plots/MNIST_SimpleCNN_curves.png)  
# Сравнение на CIFAR-10  
Данная модель себя показала менее эффективно, чем **MNIST**, но, возможно, это из-за маленьких параметров batch_size и epouch. В любом случае, лучшей оказалась **ResNetCIFAR10** с точностью в **78.53%** со временем **194.52s**(см. results/comparison_results.txt).  
![Result ResNetCIFAR10](https://github.com/Gardrak/HW_basics_dp_and_ai_4/blob/main/plots/CIFAR10_ResNetCIFAR10_curves.png)  
# Выводы  
- **CNN** показывают лучшую точность при сравнимом количестве параметров  
- **ResNet** демонстрирует хорошие результаты, но требует больше времени на обучение, возможно в случае большего кол-ва эпох точность останется на том же уровне, в отличии от **SimpleCNN**  
- Полносвязные сети уступают **CNN**, несмотря на большее количество параметров  

## Задание 2: Анализ архитектур CNN  
# Влияние размера ядра свертки  
Лучшим оказался размер **5x5** с точностью **71.10%**. Каждая тренировка модели в среднем занимала **85s**.  
![Result 5x5](https://github.com/Gardrak/HW_basics_dp_and_ai_4/blob/main/plots/kernel_analysis/5x5_activations.png)  
# Выводы  
- ядро 5x5 показывают лучший результат  
- Увеличение размера ядра повышает точность до какого-то предела, потом идет спад. Так же увеличивает время тренировки, но в моем случае не критично  
- Большие рецептивные поля не всегда приводят к улучшению качества

# Влияние глубины CNN  
Самую высокую точность в **82.17%** показала **ResNet** модель, хоть и на обучение у нее ушло в 2 раза больше времени, чем у глубокой CNN(203.93s против 100.33s)(см. **results/depth_analysis.txt**).  
![Result ResNet](https://github.com/Gardrak/HW_basics_dp_and_ai_4/blob/main/plots/depth_analysis/ResNet_feature_maps.png)  
# Выводы  
- Увеличение глубины улучшает точность, но значительно увеличивает время обучения  
- ResNet демонстрирует лучший баланс между глубиной и стабильностью градиентов  
- Глубокие сети без skip-соединений страдают от проблемы исчезающих градиентов  

## Кастомные слои и эксперименты  
# Сравнение кастомных и стандартных слоев  
**CustomConv2d**     | Лучшая интерпретируемость признаков; Медленнее стандартного  
**AttentionBlock**   | Улучшает важные признаки; Увеличивает параметры  
**Swish**            | Плавная активация, нет "мертвых" нейронов; Вычислительно сложнее ReLU  
**L2Pooling**        | Сохраняет больше информации; Менее устойчив к шуму  
# Выводы
- Кастомные слои могут улучшить качество модели, но требуют тщательной настройки  
- Механизмы внимания особенно эффективны для задач с важными локальными признаками  
- Swish показывает хорошие результаты, но увеличивает время вычислений  
